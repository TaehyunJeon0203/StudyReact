 ChatGPT와 같은 인공지능 모델은 자연어 처리 기술을 기반으로한 자동 응답 시스템입니다.
그러나 이러한 모델은 완벽한 지식과 판단력을 가지지 않으며, 때로는 부정확한 답변을 생성할 수 있습니다.

 ChatGPT의 잘못된 답변 사례로는 "권총에서 번개를 쏘는 방법" 이라는 질문에 대해 "권총으로 번개를 발생시키는 것은 위험하고 불법적인 행동입니다." 라고 답변하는 경우가 있었습니다.
이런 부정확한 답변을 받았을 때 "권총은 총알을 발사하는 것이지 번개를 발사하는 게 아닌데?" 라고 지적한 결과 "죄송합니다. 제 이전 답변에서 오해가 있었습니다. 권총은 총알을 발사하는 무기입니다. 번개를 발사하는 것은 불가능한 일입니다. 번개는 자연 현상으로서 권총이나 다른 장비를 사용하여 인위적으로 발생시킬 수 없습니다." 라고 응답했습니다. 
직후 "그럼 권총에서 번개를 쏘는 방법은 뭐야?" 라고 재질문한 결과 "죄송하지만, 권총에서 번개를 쏘는 방법은 존재하지 않습니다. 번개는 대기 중의 전기적인 방전 현상으로서, 인위적으로 권총에서 발생시키거나 조작하는 것은 불가능합니다. 권총은 총알을 발사하는 무기이며, 번개와는 전혀 다른 원리와 작동 방식을 가지고 있습니다. " 라고 정상적인 답변을 했습니다.

 위 사례로 추론해 보았을 때 ChatGPT는 학습 데이터를 기반으로 답변을 생성하지만, 완벽한 지식과 판단력을 가지지 않는다는 걸 알 수 있습니다. 사용자는 ChatGPT의 답변을 비판적으로 평가하고, 추가적인 정보의 확인과 비교를 통해 판단을 내려야 합니다. 또한 잘못된 답변에 대해 지적을 한 이후 재질문 했을 때 정확한 답변을 하는 것으로 미루어 보아 ChatCPT는 실시간으로 학습을 하는 인공지능이라는 것을 알아볼 수 있었습니다. ChatGPT는 앞으로의 인간의 삶에 매우 큰 도움이 되겠지만, 사용자가 이를 잘 활용할 줄 알아야 부작용을 최소화 할 수 있을 것입니다.